<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Gaze Detector</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
</head>
<body>
<video id="webcam" autoplay playsinline width="640" height="480"></video>
<script>
    let model;
    const video = document.getElementById('webcam');

    async function setupWebcam() {
        return new Promise((resolve, reject) => {
            const navigatorAny = navigator;
            navigator.getUserMedia = navigator.getUserMedia ||
                navigatorAny.webkitGetUserMedia || navigatorAny.mozGetUserMedia ||
                navigatorAny.msGetUserMedia;
            if (navigator.getUserMedia) {
                navigator.getUserMedia(
                    { video: true },
                    stream => {
                        video.srcObject = stream;
                        video.addEventListener('loadeddata', () => resolve(), false);
                    },
                    error => reject(error)
                );
            } else {
                reject();
            }
        });
    }

    async function loadModel() {
        model = await tf.loadLayersModel('/resources/tfjs_model/model.json');
    }

    async function sendGazeData(data) {
        const response = await fetch('/gaze-data', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(data)
        });
        return response.json();
    }

async function detectGaze() {
    const predictions = await model.predict(tf.browser.fromPixels(video));
    // 시선 감지 로직 추가
    const gazeOutside = predictions.some(prediction => prediction < 0.5); // 예: 예측 값이 0.5 미만일 때 시선이 화면 밖으로 나갔다고 가정

    if (gazeOutside) {
        const canvas = document.createElement('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const context = canvas.getContext('2d');
        context.drawImage(video, 0, 0, canvas.width, canvas.height);
        const screenshot = canvas.toDataURL('image/png');
        const timestamp = new Date().toISOString();
        const count = predictions.length; // 감지된 카운트 예시

        const data = { screenshot, timestamp, count };
        await sendGazeData(data);
    }
}

    async function main() {
        await setupWebcam();
        await loadModel();
        setInterval(detectGaze, 1000); // 1초마다 시선 감지
    }

    main();
</script>
</body>
</html>